import openai
import logging
import json
import re
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
logger = logging.getLogger(__name__)
client = OpenAI()

ASSISTANT_ID = os.getenv("OPENAI_ASSISTANT_ID")
if not ASSISTANT_ID:
    raise ValueError("‚ùó –ù–µ —É–∫–∞–∑–∞–Ω OPENAI_ASSISTANT_ID –≤ .env")

# –®–∞–±–ª–æ–Ω –∫–ª—é—á–µ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
QUESTION_PATTERN = re.compile(
    r"–ß—Ç–æ( –∏–º–µ–Ω–Ω–æ)? —Å–ª–µ–¥—É–µ—Ç —Å–¥–µ–ª–∞—Ç—å [^,]+, —á—Ç–æ–±—ã (–ø–µ—Ä–µ–π—Ç–∏ –æ—Ç [^ ]+ –∫ [^ ]+|–ø–æ–Ω—è—Ç—å [^?]+)\??",
    re.IGNORECASE
)

def validate_key_question_format(text: str) -> bool:
    if not text:
        return False
    return bool(QUESTION_PATTERN.search(text.strip()))

def try_extract_json(text: str):
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        match = re.search(r'{.*}', text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group())
            except json.JSONDecodeError:
                logger.warning("‚ùó –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –≤–ª–æ–∂–µ–Ω–Ω—ã–π JSON-–±–ª–æ–∫")
    logger.warning("‚ö†Ô∏è –û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å.")
    return {"analysis": text, "key_question": "", "field_comments": {}}

def ask_gpt_with_validation(problem_data: dict) -> dict:
    logger.debug("üßº –°—Ç–∞—Ä—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö GPT-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è GAP)
    r1 = problem_data.get("r1_as_is", "")
    r2 = problem_data.get("r2_to_be", "")
    gap = problem_data.get("gap", "")

    numbers_r1 = list(re.findall(r'\d+', r1))
    numbers_r2 = list(re.findall(r'\d+', r2))
    if gap and (not numbers_r1 or not numbers_r2):
        return {
            "analysis": "GAP —É–∫–∞–∑–∞–Ω, –Ω–æ –≤ R1 –∏–ª–∏ R2 –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å —Ä–∞–∑—Ä—ã–≤.",
            "key_question": "",
            "field_comments": {
                "gap": "–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å GAP –±–µ–∑ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ R1 –∏ R2. –£—Ç–æ—á–Ω–∏—Ç–µ: —É–∫–∞–∂–∏—Ç–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, '15 –¥–Ω–µ–π' –∏ '7 –¥–Ω–µ–π'."
            }
        }

    message = f"""
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ø—Ä–æ–±–ª–µ–º–Ω–æ–º—É –º—ã—à–ª–µ–Ω–∏—é. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–ª—è –∫–∞—Ä—Ç–æ—á–∫–∏ –ø—Ä–æ–±–ª–µ–º—ã. 

üîç –î–∞–π –¥–∏–¥–∞–∫—Ç–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –æ–±—ä—è—Å–Ω—è—é—â–∏–µ, **–ø–æ—á–µ–º—É** —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π ‚Äî —Å –æ—Ç—Å—ã–ª–∫–æ–π –∫ –∫—Ä–∏—Ç–µ—Ä–∏—è–º SMART, MECE, –ª–æ–≥–∏–∫–µ R1-R2-GAP.

‚úÖ –ï—Å–ª–∏ –ø–æ–ª–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏, —á—Ç–æ –≤—Å—ë —Ö–æ—Ä–æ—à–æ.

üìå –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–¥–æ—á—ë—Ç—ã, –ø—Ä–µ–¥–ª–æ–∂–∏ **–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è**. –ù–µ –ø–∏—à–∏ –ø—Ä–æ—Å—Ç–æ "—Ä–∞–∑–º—ã—Ç–æ" ‚Äî —É—Ç–æ—á–Ω–∏, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —É–ª—É—á—à–∏—Ç—å. –ù–∞–ø—Ä–∏–º–µ—Ä: "–£—Ç–æ—á–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –≤–º–µ—Å—Ç–æ '—É–ª—É—á—à–∏—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏' ‚Äî '—É–≤–µ–ª–∏—á–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç —Å 5 –¥–æ 10 –º–ª–Ω –¥–æ–ª–ª–∞—Ä–æ–≤'".

‚ö†Ô∏è –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø–æ–ª–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ ‚Äî **–Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ –∫–ª—é—á–µ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞**. –í–µ—Ä–Ω–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –≤ key_question.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ ‚Äî —Å—Ç—Ä–æ–≥–æ JSON:
{{
  "analysis": "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ R1, R2, GAP –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–ø–∏—Å–∞–Ω–∏—è",
  "key_question": "–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∫–ª—é—á–µ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –ò–õ–ò –ø—É—Å—Ç–æ, –µ—Å–ª–∏ –ø–æ–ª—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã",
  "field_comments": {{
    "who": "...",
    "what": "...",
    "where": "...",
    "when": "...",
    "why_now": "...",
    "r1_as_is": "...",
    "r2_to_be": "...",
    "gap": "...",
    "problem_type": "..."
  }}
}}

–î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

–ö—Ç–æ: {problem_data.get('who')}
–ß—Ç–æ: {problem_data.get('what')}
–ì–¥–µ: {problem_data.get('where')}
–ö–æ–≥–¥–∞: {problem_data.get('when')}
–ü–æ—á–µ–º—É —Å–µ–π—á–∞—Å: {problem_data.get('why_now')}
R1: {r1}
R2: {r2}
Gap: {gap}
–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã: {problem_data.get('problem_type')}
"""

    logger.info("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∞–Ω–∞–ª–∏–∑ GPT")
    thread = client.beta.threads.create()
    thread_id = thread.id

    client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=message
    )

    run = client.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=ASSISTANT_ID,
    )

    logger.info(f"‚ñ∂Ô∏è Assistant run –Ω–∞—á–∞—Ç: {run.id}")

    while True:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
        if run_status.status in ["completed", "failed", "cancelled", "expired"]:
            break

    if run_status.status != "completed":
        logger.warning(f"‚õî –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º: {run_status.status}")
        return {"analysis": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ GPT", "key_question": "", "field_comments": {}}

    messages = client.beta.threads.messages.list(thread_id=thread_id)
    content = ""

    for message in reversed(messages.data):
        if message.role == "assistant" and message.content and message.content[0].type == "text":
            content = message.content[0].text.value
            break

    logger.debug(f"üì¨ –û—Ç–≤–µ—Ç GPT: {content}")
    parsed = try_extract_json(content)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–ª—é—á–µ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
    if parsed.get("key_question") and not validate_key_question_format(parsed["key_question"]):
        logger.info("‚ö†Ô∏è –ö–ª—é—á–µ–≤–æ–π –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω—É. –û–±–Ω—É–ª—è–µ–º.")
        parsed["key_question"] = ""

    return parsed
